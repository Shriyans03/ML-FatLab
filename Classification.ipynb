{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8159730,"sourceType":"datasetVersion","datasetId":4827396}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Machine Learning - BCSE209L**\n\n### Shravan Venkatraman - 21BCE1200\n\n### Anirudh Vinodh - 21BCE1194\n\n### Shriyans A - 21BCE1121","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"}},{"cell_type":"markdown","source":"## **Import Dependencies**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom ydata_profiling import ProfileReport\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Data Exploration**","metadata":{}},{"cell_type":"code","source":"# Read the data\ndf = pd.read_csv(\"/kaggle/input/jeopardata/jeopardata.csv\")\ndf2 = pd.read_csv(\"/kaggle/input/jeopardata/jeopardata.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the size of the dataset\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get statistical information regarding the dataset\ndf.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the unique value counts of all categorical columns \nfor COLUMN in df.columns:\n    if df[COLUMN].dtype == \"object\":\n        print(f\"{COLUMN}: {len(df[COLUMN].unique())}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check columns and their datatypes\nfor COLUMN in df.columns:\n    print(f\"{COLUMN}: {df[COLUMN].dtype}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for NULL values\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Exploratory Data Analysis**","metadata":{}},{"cell_type":"code","source":"report = ProfileReport(df2)\nreport.to_notebook_iframe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group by state and calculate total correct and incorrect answers in Round One\ndf2_state_grouped = df2.groupby('Home State')[['Round One Correct Answers', 'Round One Incorrect Answers']].sum()\n\n# Calculate the number of rows and columns for subplots\nnum_states = len(df2_state_grouped)\nnum_cols = 3  # Number of columns for subplots\nnum_rows = (num_states + num_cols - 1) // num_cols  # Calculate number of rows\n\n# Create subplots\nfig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))\n\n# Flatten axes if necessary\nif num_rows == 1:\n    axes = axes.reshape(1, -1)\nelif num_cols == 1:\n    axes = axes.reshape(-1, 1)\n\n# Define colors for the bars\ncolors = ['#1f77b4', '#ff7f0e']\n\n# Iterate over each state and create a separate subplot\nfor i, (state, data) in enumerate(df2_state_grouped.iterrows()):\n    row = i // num_cols\n    col = i % num_cols\n    ax = axes[row, col]\n    data.plot(kind='bar', stacked=True, ax=ax, color=colors)  # Plot the data for the current state\n    ax.set_title(f'Distribution of Correct and Incorrect Answers in Round One for {state}')\n    ax.set_xlabel('State')\n    ax.set_ylabel('Number of Answers')\n    ax.tick_params(axis='x', rotation=45)  # Rotate x-labels\n\n# Hide empty subplots\nfor i in range(num_states, num_rows * num_cols):\n    row = i // num_cols\n    col = i % num_cols\n    fig.delaxes(axes[row, col])\n\nplt.tight_layout()  # Adjust layout of the entire figure\nplt.show()  # Show all subplots\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\ndf2_state_grouped = df2.groupby('Home State')[['Round One Score', 'Round Two Score', 'Final Jeopardy Score']].mean().reset_index()\ndf2_state_melted = df2_state_grouped.melt(id_vars='Home State', var_name='Round', value_name='Total Game Score')\nfig = px.area(df2_state_melted, x='Home State', y='Total Game Score', color='Round',\n              title='Evolution of Total Game Score for Each State',\n              labels={'Home State': 'State', 'Total Game Score': 'Total Game Score'})\nfig.update_layout(xaxis=dict(tickangle=45), yaxis=dict(title='Total Game Score'), legend_title='Round')\nfig.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport plotly.express as px\n\n# Assuming df2 contains the provided table data\n# Grouping by home state and calculating mean Round One Correct Answer Percentage\ndf2_state_mean = df2.groupby('Home State')['Round One Correct Answer Percentage'].mean().reset_index()\n\n# Plotting an interactive bar chart\nfig = px.bar(df2_state_mean, x='Home State', y='Round One Correct Answer Percentage',\n             title='Average Round One Correct Answer Percentage by Home State',\n             labels={'Round One Correct Answer Percentage': 'Mean Correct Answer Percentage'})\nfig.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ipywidgets as widgets\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\ndef show_city_stats(home_state):\n    cities = df2[df2['Home State'] == home_state]['Home City'].unique()\n    city_dropdown = widgets.Dropdown(options=cities, description='Select City:')\n    \n    def show_stats(home_city):\n        stats = df2[(df2['Home State'] == home_state) & (df2['Home City'] == home_city)].iloc[0]\n        stats = stats[['Round One Attempts', 'Round One Buzzes', 'Round One Buzz Percentage', \n                       'Round One Correct Answers', 'Round One Incorrect Answers', \n                       'Round One Correct Answer Percentage', 'Round One Daily Doubles', \n                       'Round One Score', 'Round Two Attempts', 'Round Two Buzzes', \n                       'Round Two Buzz Percentage', 'Round Two Correct Answers', \n                       'Round Two Incorrect Answers', 'Round Two Correct Answer Percentage', \n                       'Round Two Daily Double 1', 'Round Two Daily Double 2', 'Round Two Score', \n                       'Final Jeopardy Starting Score', 'Final Jeopardy Wager', \n                       'Final Jeopardy Score', 'Total Game Attempts', 'Total Game Buzzes', \n                       'Total Game Buzz Percentage', 'Total Game Correct Answers', \n                       'Total Game Incorrect Answers', 'Total Game Correct Answer Percentage', \n                       'Total Game Daily Doubles Correct', 'Total Game Daily Doubles Incorrect', \n                       'Total Game Daily Double Winnings', 'Total Game Score']]\n        \n        plt.figure(figsize=(20, 18))\n        stats.plot(kind='bar')\n        bar_color = 'red'\n        plt.title(f'Statistics for {home_city}, {home_state}')\n        plt.xlabel('Categories')\n        plt.ylabel('Values')\n        plt.xticks(rotation=45)\n        plt.show()\n    \n    widgets.interact(show_stats, home_city=city_dropdown)\nstate_dropdown = widgets.Dropdown(options=df2['Home State'].unique(), description='Select State:')\nwidgets.interact(show_city_stats, home_state=state_dropdown)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 12))\n\nc = 1\nfor COLUMN in df.columns:\n    if df[COLUMN].dtype != \"object\":\n        try:\n            plt.subplot(4, 8, c)\n            plt.hist(df[COLUMN], bins=20, color='#004C99')\n            c += 1\n        except:\n            pass\n        \nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(df['Round One Score'], bins=20, kde=True, color='skyblue', alpha=0.7)\nplt.title('Distribution of Round One Score')\nplt.xlabel('Round One Score')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.legend(['Round One Score'])\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nwinner_counts = df['Is Winner'].value_counts()\nwinner_counts.plot(kind='bar', color=['lightcoral', 'lightgreen'], alpha=0.7)\nplt.title('Contestant Winner Status')\nplt.xlabel('Winner Status')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\nplt.grid(axis='y')\nplt.legend(['Not Winner', 'Winner'])\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.scatterplot(x='Round One Buzz Percentage', y='Round One Score', data=df, color='orange', alpha=0.7)\nplt.title('Round One Buzz Percentage vs. Round One Score')\nplt.xlabel('Round One Buzz Percentage')\nplt.ylabel('Round One Score')\nplt.grid(True)\nplt.legend(['Scores'])\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.plot(df.index, df['Total Game Score'], marker='o', color='purple', linestyle='-', markersize=5, linewidth=2)\nplt.title('Total Game Score Over Episodes')\nplt.xlabel('Episode Number')\nplt.ylabel('Total Game Score')\nplt.grid(True)\nplt.legend(['Total Game Score'])\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.violinplot(y='Round One Buzz Percentage', data=df, color='lightpink', linewidth=2)\nplt.title('Violin plot of Round One Buzz Percentage')\nplt.ylabel('Round One Buzz Percentage')\nplt.grid(axis='y')\nplt.legend(['Buzz Percentage'])\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pivot_df = df.pivot_table(index='Episode Number', columns='Is Winner', values='Total Game Score')\n\n# Create the heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(pivot_df, cmap='viridis', annot=True, fmt=\".0f\", linewidths=.5)\n\nplt.xlabel(\"Winner Status\", fontsize=12)\nplt.ylabel(\"Episode Number\", fontsize=12)\nplt.yticks(rotation=0)  # Rotate y-axis labels for better readability\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.scatterplot(data=df, x='Round One Buzz Percentage', y='Final Jeopardy Wager', hue='Is Winner')\nplt.title('Correlation between Round One Buzz Percentage and Final Jeopardy Wager for Winners and Non-winners')\nplt.xlabel('Round One Buzz Percentage')\nplt.ylabel('Final Jeopardy Wager')\nplt.legend(title='Is Winner', loc='upper right')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\ndf2_grouped = df2.groupby('Home State')['Total Game Score'].sum().reset_index()\nplt.bar(df2_grouped['Home State'], df2_grouped['Total Game Score'])\nplt.xlabel('Home State')\nplt.ylabel('Total Game Score')\nplt.title('Total Game Score for Each Home State')\nplt.xticks(rotation=45, ha='right')  # Adjusting alignment to prevent overlapping\nplt.tight_layout()  # Ensuring proper spacing\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = plt.cm.tab20c.colors\n\nplt.figure(figsize=(20, 20))  # Adjust the figure size as needed\ndf2_grouped = df2.groupby('Home State')['Round Two Correct Answer Percentage'].mean().reset_index()\nplt.pie(df2_grouped['Round Two Correct Answer Percentage'], labels=df2_grouped['Home State'], autopct='%1.1f%%', colors=colors)\nplt.title('Distribution of Correct Answer Percentages in Round Two by Home State')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"contestant_counts = df2['Home State'].value_counts()\nbar_color = 'green'\nplt.figure(figsize=(16, 10))\ncontestant_counts.sort_values().plot(kind='barh', color=bar_color)\nplt.title('Number of Contestants from Each Home State')\nplt.xlabel('Number of Contestants')\nplt.ylabel('Home State')\nplt.grid(axis='x')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state_counts = df2['Home State'].value_counts(normalize=True) * 100\n\n# Plotting\nplt.figure(figsize=(12, 6))\nstate_counts.plot(kind='bar', color='skyblue')\nplt.title('Percentage of Contestants from Each Home State')\nplt.xlabel('Home State')\nplt.ylabel('Percentage of Contestants')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Extract first names from contestant names\ndf2['Contestant First Name'] = df2['Contestant First Name'].apply(lambda x: x.split()[0])\n\n# Find the top 10 highest scorers for each round\ntop_10_round_one = df2.nlargest(10, 'Round One Score')\ntop_10_round_two = df2.nlargest(10, 'Round Two Score')\nfinal_10_scores = df2.nlargest(10, 'Total Game Score')\n\n# Create subplots\nfig, axs = plt.subplots(3, 1, figsize=(10, 15))\n\n# Plot top 10 highest scorers for Round One\naxs[0].bar(top_10_round_one['Contestant First Name'], top_10_round_one['Round One Score'], color='skyblue')\naxs[0].set_title('Top 10 highest scorers for Round One')\naxs[0].set_ylabel('Round One Score')\naxs[0].set_xlabel('Contestant First Name')\naxs[0].tick_params(axis='x', rotation=45)\n\n# Plot top 10 highest scorers for Round Two\naxs[1].bar(top_10_round_two['Contestant First Name'], top_10_round_two['Round Two Score'], color='lightgreen')\naxs[1].set_title('Top 10 highest scorers for Round Two')\naxs[1].set_ylabel('Round Two Score')\naxs[1].set_xlabel('Contestant First Name')\naxs[1].tick_params(axis='x', rotation=45)\n\n# Plot final 10 highest scores\naxs[2].bar(final_10_scores['Contestant First Name'], final_10_scores['Total Game Score'], color='lightcoral')\naxs[2].set_title('Final 10 highest scores')\naxs[2].set_ylabel('Total Game Score')\naxs[2].set_xlabel('Contestant First Name')\naxs[2].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\nimport plotly.express as px\nfrom ipywidgets import interact\n\n# Define a function to create the interactive pie chart\ndef create_pie_chart(home_state):\n    # Filter the DataFrame for the selected home state\n    filtered_df = df2[df2['Home State'] == home_state]\n    \n    # Count the number of winners and non-winners\n    winner_counts = filtered_df['Is Winner'].value_counts()\n    \n    # Create a pie chart\n    fig = px.pie(names=winner_counts.index, values=winner_counts.values, title=f'Distribution of Winners in {home_state}',\n                 labels={'index': 'Is Winner'})\n\n    # Show the figure\n    fig.show()\n\n# Get unique home states\nhome_states = df2['Home State'].unique()\n\n# Create an interactive widget for selecting the home state\ninteract(create_pie_chart, home_state=home_states)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"episode_counts = df2['Episode Title'].value_counts()\n\n# Plotting\nplt.figure(figsize=(8, 8))\nplt.pie(episode_counts, labels=episode_counts.index, autopct='%1.1f%%', colors=plt.cm.tab10.colors)\nplt.title('Split of Different Episode Types')\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"winners = df[df['Is Winner'] == 1]\nnon_winners = df[df['Is Winner'] == 0]\n\n# Create scatter plot\nplt.figure(figsize=(10, 6))\nplt.scatter(non_winners['Round One Attempts'], non_winners['Round One Buzzes'], color='blue', label='Non-Winner')\nplt.scatter(winners['Round One Attempts'], winners['Round One Buzzes'], color='red', label='Winner')\nplt.ylabel('Round One Attempts')\nplt.xlabel('Round One Buzzes')\nplt.title('Relationship between Round One Attempts, Round One Buzzes, and Winner Status')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Group by home state and count the number of winners in each state\nwinners_by_state = df2[df2['Is Winner'] == True].groupby('Home State')['Is Winner'].count().sort_values(ascending=False)\n\n# Select the top few best performing home states\ntop_states = winners_by_state.head(10)\n\n# Plot the top performing home states\nplt.figure(figsize=(10, 6))\ntop_states.plot(kind='bar', color='skyblue')\nplt.title('Top Performing Home States by Number of Winners')\nplt.xlabel('Home State')\nplt.ylabel('Number of Winners')\nplt.xticks(rotation=45)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop duplicate columns\ndf = df.drop_duplicates()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop columns which do not seem like factors to affect the output\ndf = df.drop(['Episode Date', 'Home State', 'Contestant Last Name', 'Contestant First Name', 'Home City'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot correlation matrix to find out columns which are highly correlated\ncorr_matrix = df.drop(['Episode Title', 'Is Winner'], axis=1).corr().abs()\n\nplt.figure(figsize=(10, 10))\nsns.heatmap(corr_matrix, cmap=\"YlGnBu\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform one-hot encoding\none_hot_encoded = pd.get_dummies(df['Episode Title'], prefix='Title').astype(int)\n\n# Concatenate the one-hot encoded columns with the original DataFrame and drop existing column\ndf = pd.concat([df, one_hot_encoded], axis=1)\ndf = df.drop('Episode Title', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label Encode the output column\nle = preprocessing.LabelEncoder()\nencoded_values = le.fit_transform(df['Is Winner'])\ndf['Is Winner'] = encoded_values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop('Is Winner', axis=1)\ny = df['Is Winner']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA(n_components=25)\nprincipalComponents = pca.fit_transform(X)\nprincipalDf = pd.DataFrame(data = principalComponents )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_pca = principalDf\ny_pca = y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Train Vanilla Models**","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a dictionary of models\nmodels = {\n    'Adaboost': AdaBoostClassifier(),\n    'XGBoost': XGBClassifier(n_estimators=100),\n    'Random Forest': RandomForestClassifier(),\n    'SVM': SVC(),\n    'Logistic Regression': LogisticRegression(),\n    'Decision Tree': DecisionTreeClassifier(max_depth=4),\n    'Extra Decision Tree': ExtraTreeClassifier(max_depth=4),\n    'Naive Bayes': GaussianNB(),\n    'Extra Trees': ExtraTreesClassifier(max_depth=4),\n    'KNN': KNeighborsClassifier(),\n    'MLP': MLPClassifier(\n        hidden_layer_sizes=(200,),\n        max_iter=300,\n        early_stopping=True,\n    )\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit and predict using each model\nfor name, model in models.items():\n    print(f\"Training model: {name}...\")\n    model.fit(X_train, y_train)\n    score = model.score(X_test, y_test)\n    print(f'{name}: Accuracy - {score:.4f}\\n')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Train Ensemble Models**","metadata":{}},{"cell_type":"code","source":"# Create the individual classifiers\nxgbc = XGBClassifier(n_estimators=100)\nrf = RandomForestClassifier(random_state=42)\nsvc = SVC()\n\n# Create a voting classifier with 'hard' voting\nvoting_clf = VotingClassifier(estimators=[('xgbc', xgbc), ('rf', rf), ('svc', svc)], voting='hard')\n\n# Fit the voting classifier on the training data\nvoting_clf.fit(X_train, y_train)\nscore = model.score(X_test, y_test)\nprint(f'Ensembling using Voting Classifier (XGBoost, Random Forest and Support Vector Machines): Accuracy - {score:.4f}\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Results**","metadata":{}},{"cell_type":"code","source":"y_pred=models['Random Forest'].predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(y_test, y_pred):\n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.xticks([0.5, 1.5], [\"Not Winner\", \"Winner\"])\n    plt.yticks([0.5, 1.5], [\"Not Winner\", \"Winner\"])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred, target_names=[\"Not Winner\", \"Winner\"]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **PCA Training**","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a dictionary of models\nmodels = {\n    'Adaboost': AdaBoostClassifier(),\n    'XGBoost': XGBClassifier(n_estimators=100),\n    'Random Forest': RandomForestClassifier(),\n    'SVM': SVC(),\n    'Logistic Regression': LogisticRegression(),\n    'Decision Tree': DecisionTreeClassifier(max_depth=4),\n    'Extra Decision Tree': ExtraTreeClassifier(max_depth=4),\n    'Naive Bayes': GaussianNB(),\n    'Extra Trees': ExtraTreesClassifier(max_depth=4),\n    'KNN': KNeighborsClassifier(),\n    'MLP': MLPClassifier(\n        hidden_layer_sizes=(200,),\n        max_iter=300,\n        early_stopping=True,\n    )\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Fit and predict using each model\nfor name, model in models.items():\n    print(f\"Training model: {name}...\")\n    model.fit(X_train, y_train)\n    score = model.score(X_test, y_test)\n    print(f'{name}: Accuracy - {score:.4f}\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the individual classifiers\nxgbc = XGBClassifier(n_estimators=100)\nrf = RandomForestClassifier(random_state=42)\nsvc = SVC()\n\n# Create a voting classifier with 'hard' voting\nvoting_clf = VotingClassifier(estimators=[('xgbc', xgbc), ('rf', rf), ('svc', svc)], voting='hard')\n\n# Fit the voting classifier on the training data\nvoting_clf.fit(X_train, y_train)\nscore = model.score(X_test, y_test)\nprint(f'Ensembling using Voting Classifier (XGBoost, Random Forest and Support Vector Machines): Accuracy - {score:.4f}\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=models['Random Forest'].predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(y_test, y_pred):\n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.xticks([0.5, 1.5], [\"Not Winner\", \"Winner\"])\n    plt.yticks([0.5, 1.5], [\"Not Winner\", \"Winner\"])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred, target_names=[\"Not Winner\", \"Winner\"]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n\n\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]}]}